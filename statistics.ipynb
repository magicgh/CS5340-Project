{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\77452\\OneDrive - National University of Singapore\\Desktop\\5340\\new-results\\result-financial\\Llama-2-7b-hf_financial_prompt2\\Llama-2-7b-hf_financial_random_prompt2.json\n",
      "mean_value_EU 0.5468373603020318\n",
      "mean_value_AU 0.07709989825591873\n",
      "std_value_EU 0.2877731255455206\n",
      "std_value_AU 0.10518822262817903\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the JSON file into a DataFrame\n",
    "file_path = \"C:\\\\Users\\\\77452\\\\OneDrive - National University of Singapore\\\\Desktop\\\\5340\\\\new-results\\\\result-financial\\\\Llama-2-7b-hf_financial_prompt2\\\\Llama-2-7b-hf_financial_random_prompt2.json\"\n",
    "print(file_path)\n",
    "\n",
    "df = pd.read_json(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to understand its structure\n",
    "\n",
    "mean_value_AU = df['AU'].mean()\n",
    "std_dev_AU = df['AU'].std()\n",
    "mean_value_EU = df['EU'].mean()\n",
    "std_dev_EU = df['EU'].std()\n",
    "print(\"mean_value_EU \" + str(mean_value_EU))\n",
    "print(\"mean_value_AU \" + str(mean_value_AU))\n",
    "print(\"std_value_EU \" + str(std_dev_EU))\n",
    "print(\"std_value_AU \" + str(std_dev_AU))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_precision_EU_AUPR 0.6703317787277652\n",
      "roc_auc_EU_AUROC 0.5235063762440524\n",
      "average_precision_AU_AUPR 0.6204630889920986\n",
      "roc_auc_AU_AUROC 0.46918402337448895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# df = pd.read_json(\"results/70b_sentiment_processed_class.json\") \n",
    "# df = pd.read_json(\"C:\\\\Users\\\\77452\\\\OneDrive - National University of Singapore\\Desktop\\\\5340\\\\results-financial\\\\results-financial\\\\gemma-2b-financial_prompt2\\\\gemma-2b_financial_random.json\") \n",
    "\n",
    "# def most_common_element(items):\n",
    "#     answers = []\n",
    "#     for i in range(len(items)):\n",
    "#         for j in range(len(items[i][0])):\n",
    "#             res = re.findall(r'\\d+\\.\\d+|\\d+', ''.join(items[i][0][j]))\n",
    "#             if res:\n",
    "#                 answers.append(int(float(res[0])))\n",
    "#     try:\n",
    "#         pred = Counter(answers).most_common()[0][0]\n",
    "#     except:\n",
    "#         pred = None\n",
    "#     return pred\n",
    "\n",
    "# df['Predicted_Label'] = df['Predicted_Label'].apply(most_common_element)\n",
    "df['Predicted_Label'] = df['Predicted_Label']\n",
    "\n",
    "df = df.replace(to_replace='None', value=np.nan).dropna() \n",
    "valid_predictions = df[\"Predicted_Label\"] != \"None\" \n",
    "# For these rows, compute the \"Is_Correct\" column \n",
    "df.loc[valid_predictions, \"Is_Correct\"] = (df.loc[valid_predictions, \"Label\"] != df.loc[valid_predictions, \"Predicted_Label\"].astype(int)).astype(int) \n",
    "# Calculating the accuracy \n",
    "accuracy = accuracy_score(df[\"Label\"], df[\"Predicted_Label\"].astype(int)) \n",
    "# Calculating AUPR \n",
    "average_precision_AU = average_precision_score(df[\"Is_Correct\"], df[\"AU\"]) \n",
    "average_precision_EU = average_precision_score(df[\"Is_Correct\"], df[\"EU\"]) \n",
    "# Calculating AUROC \n",
    "roc_auc_AU = roc_auc_score(df[\"Is_Correct\"], df[\"AU\"]) \n",
    "roc_auc_EU = roc_auc_score(df[\"Is_Correct\"], df[\"EU\"])\n",
    "\n",
    "\n",
    "\n",
    "print(\"average_precision_EU_AUPR \" + str(average_precision_EU))\n",
    "print(\"roc_auc_EU_AUROC \" + str(roc_auc_EU))\n",
    "print(\"average_precision_AU_AUPR \" + str(average_precision_AU))\n",
    "print(\"roc_auc_AU_AUROC \" + str(roc_auc_AU))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
